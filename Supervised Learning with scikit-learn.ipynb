{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Classification**: Target variable consists of categories\n",
    "- **Regression**: Target variable is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions:\n",
    "- Feature = predictor variable = independent variable\n",
    "- target variable = response variable = dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scikit-learn syntax\n",
    "\n",
    "from sklearn.module import Model   # import model\n",
    "model = Model()   # intialize model\n",
    "model.fit(X, y)   # fit model with training data\n",
    "predictions = model.preict(X_new)   # use new data to predict\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = chun_df[['total_day_charge', 'total_eve_charge']]\n",
    "y = churn_df['churn'].values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X, y)\n",
    "\n",
    "y_pred = knn.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = churn_df.drop(\"churn\", axis = 1).values\n",
    "y = churn_df[\"churn\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_text_split(X, y, test_size = 0.3, random_state = 21, stratify = y)   \n",
    "# Note: stratify to ensure the target label proportions reflect that of the original data set\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test))   # use .score function to calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model complexity and over/underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors = np.arrange(1, 26)\n",
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "plt.plot(neighbors, train_accuracies.values(), label = \"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label = \"Testing Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_bmi, y)\n",
    "predictions = reg.predict(X_bmi)\n",
    "plt.scatter(X_bmi, y)\n",
    "plt.plot(X_bmi, predictions)\n",
    "plt.ylabel(\"Blood Glucose (mg/dl)\")\n",
    "plt.xlabel(\"Body Mass Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Square (OLS)\n",
    "\n",
    "- **Residual Sum of Squared:** $RSS = \\Sigma_{i = 1}^n (y_i - \\hat{y_i})^2$ <br><br>\n",
    "- **Mean Squared Error:** $MSE = \\frac{1}{n} \\Sigma_{i = 1}^n (y_i - \\hat{y_i})^2$ <br><br>\n",
    "- **Root Mean Squared Error:** $RMSE = \\sqrt{MSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train, y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "reg_all.score(X_test, y_test)   # calculates R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred, squared = False)   # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits = 6, shuffle = True, random_state = 42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "cv_results = cross_val_score(reg, X, y, kf)\n",
    "\n",
    "print(cv_results)\n",
    "print(np.mean(cv_results), np.std(cv_results))\n",
    "print(np.quantile(cv_results, [0.025, 0.975]))   # 95% CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Regression\n",
    "- **Ridge regression:** OLS loss function + $\\alpha \\times \\Sigma_{i = 1}^n a_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "score = []\n",
    "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    scores.append(ridge.score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Lasso regression:** OLS loss function + $\\alpha \\times \\Sigma_{i = 1}^n |a_i|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "score = []\n",
    "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    scores.append(lasso.score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso for feature selection** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.liner_model import Lasso\n",
    "\n",
    "X = diabetes_df.drop(\"glucose\", ais = 1).values\n",
    "y = diabetes_df[\"glucose\"].values\n",
    "names = diabetes_df.drop(\"glucose\", axis = 1).columns\n",
    "\n",
    "lasso = Lasso(alpha = 0.1)\n",
    "lass_coe = lasso.fit(X, y).coef_\n",
    "\n",
    "plt.bar(names, lasso_coef)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Tuning\n",
    "\n",
    "- **Class Inbalance**\n",
    "- **Confusion Metrix**\n",
    "    - **Accuracy** = $\\frac{\\text{true positives} + \\text{true negatives}}{\\text{true positives} + \\text{true negatives} + \\text{false positives} + \\text{false negatives}}$ <br><br>\n",
    "    - **Precision** = $\\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}$ <br><br>\n",
    "    - **Recall** = $\\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}$ <br><br>\n",
    "    - **F1 Score** = $2 \\times \\frac{precision \\times recall}{precision + recall}$ <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Receiver Operating Characteristic (ROC) curve** for tunning thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pre_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Logistic Regression ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Area Under ROC Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperpaameter tuning\n",
    "- **Grid search cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selecion import GridSearchCV\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "param_grid = {\"alpha\": np.arrange(0.0001, 1, 10),\n",
    "             \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv = kf)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selecion import RandomizedSearchCV\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "param_grid = {\"alpha\": np.arrange(0.0001, 1, 10),\n",
    "             \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = RandomizedSearchCV(ridge, param_grid, cv = kf)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating on the test set\n",
    "test_score = ridge_cv.score(X_test, y_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing and Pipelines\n",
    "### Preprocessing\n",
    "#### Dealing with categorical features:\n",
    "- scikit-learn: **OneHotEncoder()**\n",
    "- pandas: **get_dummies()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv('music.csv')\n",
    "music_dummies = pd.get_dummies(music_df[\"genre\"], drop_first = True)\n",
    "music_dummies = pd.concat([music_df, music_dummies], axis = 1)\n",
    "music_dummies = music_dummies.drop(\"genre\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression with dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = music_dummies.drop(\"popularity\", axis = 1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg_cv = cross_val_score(linreg, X_train, y_train, cv = kf, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "print(np.sqrt(-linreg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "- drop\n",
    "- imputing values: mean/median/mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = music_df.dropna(subset = ['genre', 'popularity', 'loudness', 'liveness', 'tempo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation with sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "X_cat = music_df['genre'].values.reshape(-1, 1)\n",
    "X_num = music_df.drop(['genre', 'popularity'], axis = 1).values\n",
    "y = music_df['popularity'].values\n",
    "\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size = 0.2, random_state = 12)\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size = 0.2, random_state = 12)\n",
    "\n",
    "imp_cat = SimpleImputer(strategy = 'most_frequent')\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "X_test_cat = imp_cat.fit_transform(X_test_cat)\n",
    "\n",
    "imp_num = SimpleImputer()   # by default fill with mean\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "X_test_num = imp_num.fit_transform(X_test_num)\n",
    "\n",
    "X_train = np.append(X_train_num, X_train_cat, axis = 1)\n",
    "X_test = np.append(X_test_num, X_test_cat, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "music_df = music_df.dropna(subset = ['genre', 'popularity', 'loudness', 'liveness', 'tempo'])\n",
    "music_df['genre'] = np.where(music_df['genre'] == 'Rock', 1, 0)\n",
    "X = music_df.drop(\"genre\", axis = 1).values\n",
    "y = music_df['genres'].values\n",
    "\n",
    "steps = [(\"imputation\", SimpleImputer()),\n",
    "        (\"logistic_regression\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Centering and scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = music_df.drop(\"genre\", axis = 1).values\n",
    "y = music_df['genres'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling with pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors = 6))]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_scaled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {\"knn__n_neighbors\": np.arrange(1, 50)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = music.drop(\"genre\", axis=1).values\n",
    "y = music[\"genre\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(),\n",
    "\"Decision Tree\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "for model in models.values():\n",
    "kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "results.append(cv_results)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
